#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ëª¨ë“  ìë™í™” ë¡œì§ê³¼ ì•ˆì •ì„± ê°•í™” ê¸°ëŠ¥ì´ í¬í•¨ëœ ìë™ í¬ìŠ¤íŒ… ìŠ¤í¬ë¦½íŠ¸ ìµœì¢… ì™„ì„±ë³¸.
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì„¤ì •ëœ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ 'ë¼ìš´ë“œ-ë¡œë¹ˆ' ë°©ì‹ìœ¼ë¡œ ìˆœíšŒí•˜ë©°,
ë°œí–‰ ê¸°ë¡ì„ ì²´í¬í•˜ì—¬ ì¤‘ë³µ ì—†ì´ ìƒˆë¡œìš´ ê¸€ì„ ê³µí‰í•˜ê²Œ ë°œí–‰í•©ë‹ˆë‹¤.
(v34.3: Google Maps ì •í™•ë„ë¥¼ ìœ„í•´ Place ID ì ìš©)
"""

import os
import requests
import json
import time
import re
import google.generativeai as genai
import urllib.parse
import random
import html
import traceback
import itertools
from dotenv import load_dotenv
from PIL import Image
from io import BytesIO

# ##############################################################################
# ì‚¬ìš©ì ì„¤ì • (ìë™í™” ì œì–´)
# ##############################################################################
MAX_POSTS_PER_RUN = 10
PUBLISHED_LOG_FILE = "published_log.txt"
POST_DELAY_SECONDS = 15
# ##############################################################################

try:
    from places_config_overseas import TARGET_PLACES_OVERSEAS
except ImportError:
    print("[âŒ] ì˜¤ë¥˜: 'places_config_overseas.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜, TARGET_PLACES_OVERSEAS ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

CATEGORY_ID_TO_NAME = {
    23: "ì¼ë³¸", 25: "ì¤‘êµ­/í™ì½©", 30: "íƒœêµ­", 31: "ë² íŠ¸ë‚¨", 32: "í•„ë¦¬í•€", 33: "ë§ë ˆì´ì‹œì•„", 34: "ì‹±ê°€í¬ë¥´", 35: "ì¸ë„ë„¤ì‹œì•„",
    36: "ì„œìœ ëŸ½", 37: "ë™ìœ ëŸ½", 52: "ë‚¨ìœ ëŸ½", 38: "ë¶ìœ ëŸ½", 39: "ì˜êµ­/ì•„ì¼ëœë“œ", 40: "ë¯¸êµ­", 41: "ìºë‚˜ë‹¤", 42: "ë©•ì‹œì½”",
    43: "í˜¸ì£¼", 44: "ë‰´ì§ˆëœë“œ", 45: "í”¼ì§€ ë° ë‚¨íƒœí‰ì–‘ íœ´ì–‘ì§€", 46: "ë‘ë°”ì´/ì•„ëì—ë¯¸ë¦¬íŠ¸", 47: "í„°í‚¤", 48: "ì´ì§‘íŠ¸", 49: "ëª¨ë¡œì½”", 50: "ê¸°íƒ€"
}

def load_configuration():
    print("[âš™ï¸] 1. ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    load_dotenv()
    config = {
        "gemini_api_key": os.getenv("GEMINI_API_KEY"),
        "google_places_api_key": os.getenv("GOOGLE_PLACES_API_KEY"),
        "pexels_key": os.getenv("PEXELS_API_KEY"),
        "wp_url": os.getenv("WP_URL"),
        "wp_api_base": os.getenv("WP_API_BASE"),
        "wp_user": os.getenv("WP_USER"),
        "wp_app_pass": os.getenv("WP_APP_PASS"),
    }
    if not all(config.values()):
         print("[âŒ] ì˜¤ë¥˜: .env íŒŒì¼ì— í•„ìš”í•œ ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
         return None
    try:
        genai.configure(api_key=config["gemini_api_key"])
        print("[âœ…] Gemini APIê°€ ì„±ê³µì ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"[âŒ] Gemini API êµ¬ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    return config

def get_final_redirected_url(initial_url):
    try:
        response = requests.get(initial_url, allow_redirects=True, timeout=15, stream=True)
        response.raise_for_status()
        return response.url
    except requests.RequestException:
        return None

def validate_image_url(url):
    try:
        response = requests.get(url, timeout=15, allow_redirects=True)
        response.raise_for_status()
        content_type = response.headers.get('Content-Type', '')
        if 'image/' not in content_type: return False
        content_length = int(response.headers.get('Content-Length', 0))
        if content_length < 10240: return False
        try:
            img = Image.open(BytesIO(response.content))
            img.verify()
            if img.size[0] < 100 or img.size[1] < 100: return False
            return True
        except Exception: return False
    except requests.RequestException: return False

def get_google_place_details(cfg, place_name, category_name):
    search_query = f"{place_name} in {category_name} tourist attraction landmark"
    print(f"[ğŸ”] '{search_query}': Google Places APIì—ì„œ ì •ë³´ ë° ì‚¬ì§„ ì¶œì²˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    api_key = cfg["google_places_api_key"]
    search_url = "https://places.googleapis.com/v1/places:searchText"
    search_headers = {
        "Content-Type": "application/json",
        "X-Goog-Api-Key": api_key,
        "X-Goog-FieldMask": "places.id,places.displayName,places.formattedAddress,places.websiteUri,places.editorialSummary,places.photos.name,places.photos.authorAttributions,places.regularOpeningHours"
    }
    search_data = {"textQuery": search_query, "languageCode": "ko"}
    details = {}
    try:
        response = requests.post(search_url, headers=search_headers, json=search_data, timeout=20)
        response.raise_for_status()
        data = response.json()
        places = data.get('places', [])
        if not places: return None
        place_info = places[0]
        details['place_id'] = place_info.get('id')
        details['overview'] = place_info.get('editorialSummary', {}).get('text', 'No information available.')
        details['address'] = place_info.get('formattedAddress', 'No information available.')
        details['homepage'] = place_info.get('websiteUri', 'No information available.')
        opening_hours_texts = place_info.get('regularOpeningHours', {}).get('weekdayDescriptions', [])
        details['opening_hours'] = " \n ".join(opening_hours_texts) if opening_hours_texts else 'No information available.'
        image_data = []
        photos = place_info.get('photos', [])
        for photo in photos:
            photo_name = photo.get('name')
            photo_url = f"https://places.googleapis.com/v1/{photo_name}/media?maxHeightPx=1200&key={api_key}"
            attribution_html = "Photo from Google"
            author_attributions = photo.get('authorAttributions', [])
            if author_attributions:
                attribution_html = author_attributions[0].get('displayName', 'Google')
            image_data.append({
                "url": photo_url, "source": "Google", "attribution": attribution_html
            })
        details['images'] = image_data
        print(f"[âœ…] Google Places: ìƒì„¸ ì •ë³´ ë° ì´ë¯¸ì§€/ì¶œì²˜ {len(details['images'])}ê°œ ìˆ˜ì§‘ ì™„ë£Œ.")
        return details
    except requests.exceptions.RequestException as e:
        print(f"[âŒ] '{search_query}': Google Places API ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"[âŒ] '{search_query}': Google Places ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def search_pexels_images(cfg, place_name, category_name):
    search_query = f"{place_name} {category_name} travel landscape landmark -food -restaurant -dish"
    print(f"[ğŸ”] '{search_query}': Pexels APIì—ì„œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ë° ì¶œì²˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    try:
        headers = {"Authorization": cfg['pexels_key']}
        params = {"query": search_query, "per_page": 15, "locale": "ko-KR"}
        response = requests.get("https://api.pexels.com/v1/search", headers=headers, params=params, timeout=20)
        response.raise_for_status()
        results = response.json().get('photos', [])
        image_data = []
        for item in results:
            image_data.append({
                'url': item['src']['large2x'],
                'source': 'Pexels',
                'attribution': f"Photo by {item.get('photographer', 'Unknown')} on Pexels",
                'photographer': item.get('photographer', 'Unknown'),
                'photographer_url': item.get('photographer_url')
            })
        print(f"[âœ…] Pexels: ì´ë¯¸ì§€/ì¶œì²˜ {len(image_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ.")
        return image_data
    except requests.exceptions.RequestException as e:
        print(f"[âŒ] '{search_query}': Pexels API ìš”ì²­ ì˜¤ë¥˜: {e}")
        return []
    except Exception as e:
        print(f"[âŒ] '{search_query}': Pexels ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def generate_gemini_content(place_name, place_details, context_images):
    print(f"[ğŸ¤–] '{place_name}': Gemini AIë¡œ ê°•í™”ëœ ë³¸ë¬¸, í…Œì´ë¸”, FAQ ë°ì´í„° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    model = genai.GenerativeModel('gemini-1.5-pro-latest')
    prompt_parts = [
        f"ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ ì›”ë“œ íŠ¸ë˜ë¸” ì „ë¬¸ ë¸”ë¡œê±°ì´ì SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ì œê³µë˜ëŠ” í•´ì™¸ ì—¬í–‰ì§€ '{place_name}'ì— ëŒ€í•œ ê³µì‹ ì •ë³´ì™€ ì‹¤ì œ ì‚¬ì§„ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, í•œêµ­ì¸ ì—¬í–‰ìë“¤ì„ ìœ„í•œ ë§¤ìš° ìƒì„¸í•˜ê³  ìœ ìš©í•œ ë¸”ë¡œê·¸ ê¸€ê³¼ ë¶€ê°€ ì •ë³´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n\n"
        f"### ê³µì‹ ì •ë³´ ìš”ì•½ (Official Information from Google Places):\n"
        f"- ì£¼ì†Œ (Address): {place_details.get('address')}\n- ìš´ì˜ì‹œê°„ (Hours): {place_details.get('opening_hours')}\n- í™ˆí˜ì´ì§€ (Homepage): {place_details.get('homepage')}\n- ê°œìš” (Overview):\n{place_details.get('overview')}\n\n"
        f"### ì°¸ê³  ì‚¬ì§„ (Reference Photos):\n(ì•„ë˜ ì²¨ë¶€ëœ ì‚¬ì§„ë“¤ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ì§„ì˜ ë¶„ìœ„ê¸°ì™€ íŠ¹ì§•ì„ ê¸€ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì„¸ìš”.)\n",
    ]
    image_count = 0
    for img_data in context_images:
        if image_count >= 3: break
        try:
            response_img = requests.get(img_data['url'], timeout=15)
            response_img.raise_for_status()
            img_bytes = response_img.content
            mime_type = response_img.headers.get('Content-Type', 'image/jpeg')
            prompt_parts.append({"mime_type": mime_type, "data": img_bytes})
            image_count += 1
        except Exception as e:
            print(f"[âš ï¸] '{place_name}': Geminiìš© ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ({img_data['url']}) ì˜¤ë¥˜: {e}")

    prompt_parts.append(f"\n### ì§€ì‹œì‚¬í•­ ###\n1. ìœ„ ì •ë³´ì™€ ì‚¬ì§„ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ 'ë¸”ë¡œê·¸ ê¸€ í˜•ì‹'ì— ë§ì¶° ë§¤ìš° ìƒì„¸í•˜ê³  ìœ ìš©í•œ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n2. ê·¸ ë‹¤ìŒ, ê¸€ ë‚´ìš©ê³¼ ê³µì‹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ 'ìš”ì•½ í…Œì´ë¸” ë°ì´í„°'ì™€ 'FAQ ë°ì´í„°'ë¥¼ í˜•ì‹ì— ë§ì¶° ê°ê° ìƒì„±í•´ì£¼ì„¸ìš”.\n\n"
                        f"--- ë¸”ë¡œê·¸ ê¸€ í˜•ì‹ ì‹œì‘ ---\n# ì œëª©: [ì—¬ê¸°ì— '{place_name}'ì„(ë¥¼) í•µì‹¬ í‚¤ì›Œë“œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œí‚¤ë©´ì„œ, ìµœì‹  SEO íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ì—¬ ì‚¬ìš©ìì˜ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ê³  ë°˜ë“œì‹œ í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” 15ìì—ì„œ 40ì ì‚¬ì´ì˜ ë§¤ìš° ë§¤ë ¥ì ì¸ ì œëª©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.]\n\n"
                        f"[ì—¬ê¸°ì— '{place_name}'ì— ëŒ€í•œ í¥ë¯¸ë¥¼ ìœ ë°œí•˜ëŠ” ì„œë¡  ì‘ì„±. ë°©ë¬¸í•´ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ê°•ë ¥í•˜ê²Œ ì œì‹œí•˜ì„¸ìš”.]\n\n"
                        f"#### [ì´ê³³ì˜ ì—­ì‚¬ì™€ ìˆ¨ê²¨ì§„ ì´ì•¼ê¸°]\n[ë‹¨ìˆœ ì •ë³´ ë‚˜ì—´ì´ ì•„ë‹Œ, í¥ë¯¸ë¡œìš´ ì¼í™”ë‚˜ ë°°ê²½ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìƒì„¸íˆ ì„œìˆ ]\n\n"
                        f"#### [ë†“ì¹˜ë©´ í›„íšŒí•˜ëŠ” í•µì‹¬ ë³¼ê±°ë¦¬ TOP 3]\n[ê°€ì¥ ì¤‘ìš”í•œ ë³¼ê±°ë¦¬ë‚˜ ì²´í—˜í™œë™ 3ê°€ì§€ë¥¼ ìˆœìœ„ë‚˜ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìƒì„¸íˆ ì„¤ëª…]\n\n"
                        f"#### [ì°¾ì•„ê°€ëŠ” ë°©ë²•: êµí†µí¸ ì™„ë²½ ì •ë¦¬]\n[ì§€í•˜ì² , ë²„ìŠ¤, íƒì‹œ ë“± ëŒ€ì¤‘êµí†µ ì´ìš©ë²•ê³¼ ìê°€ìš© ì´ìš© ì‹œ ì£¼ì°¨ ì •ë³´ë¥¼ ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±]\n\n"
                        f"#### [ì—¬í–‰ ê¿€íŒ: ìµœì  ë°©ë¬¸ ì‹œê¸°, ì…ì¥ë£Œ, ì£¼ë³€ ì •ë³´]\n[ê°€ì¥ ì—¬í–‰í•˜ê¸° ì¢‹ì€ ê³„ì ˆì´ë‚˜ ì‹œê°„ëŒ€, ê³µì‹ì ì¸ ì…ì¥ë£Œ ì •ë³´, ì˜ˆìƒì¹˜ ëª»í•œ ë¹„ìš©, ì£¼ë³€ì˜ ë‹¤ë¥¸ ë³¼ê±°ë¦¬ ë“±ì„ êµ¬ì²´ì ì¸ íŒê³¼ í•¨ê»˜ ì‘ì„±]\n\n"
                        f"#### [í˜„ì§€ì¸ ì¶”ì²œ: ì£¼ë³€ ë§›ì§‘ & íŠ¹ìƒ‰ìˆëŠ” ì¹´í˜]\n[ê´€ê´‘ì§€ ê·¼ì²˜ì—ì„œ ì‹ì‚¬í•˜ê±°ë‚˜ ì°¨ë¥¼ ë§ˆì‹œê¸° ì¢‹ì€, í˜„ì§€ì¸ì—ê²Œ ì¸ê¸° ìˆëŠ” ì‹ë‹¹ì´ë‚˜ ì¹´í˜ 1~2ê³³ì„ ì¶”ì²œ ì´ìœ ì™€ í•¨ê»˜ ì†Œê°œ]\n"
                        f"--- ë¸”ë¡œê·¸ ê¸€ í˜•ì‹ ë ---\n\n"
                        f"--- ìš”ì•½ í…Œì´ë¸” ë°ì´í„° í˜•ì‹ ì‹œì‘ ---\n<TABLE_DATA>\n"
                        f"ìœ„ì¹˜: [{place_details.get('address')}]\n"
                        f"ìš´ì˜ì‹œê°„: [í•µì‹¬ ìš´ì˜ ì‹œê°„ê³¼ íœ´ë¬´ì¼ì„ ìš”ì•½í•˜ì—¬ ê¸°ì…]\n"
                        f"ì…ì¥ë£Œ: [ì•Œë ¤ì§„ ì…ì¥ë£Œ ì •ë³´ ê¸°ì…, ë¬´ë£Œì¸ ê²½ìš° 'ë¬´ë£Œ'ë¼ê³  ëª…ì‹œ, ë³€ë™ ê°€ëŠ¥ì„± ì–¸ê¸‰]\n"
                        f"ê³µì‹ ì›¹ì‚¬ì´íŠ¸: [{place_details.get('homepage')}]\n"
                        f"ì¶”ì²œ ë°©ë¬¸ ì‹œê¸°: [ê°€ì¥ ë°©ë¬¸í•˜ê¸° ì¢‹ì€ ê³„ì ˆì´ë‚˜ ìš”ì¼ ëª…ì‹œ]\n"
                        f"ë°©ë¬¸ê¿€íŒ: [ê°€ì¥ ì¤‘ìš”í•œ íŒ í•˜ë‚˜ë¥¼ 30ì ë‚´ì™¸ë¡œ ìš”ì•½í•˜ì—¬ ê¸°ì…]\n"
                        f"</TABLE_DATA>\n--- ìš”ì•½ í…Œì´ë¸” ë°ì´í„° í˜•ì‹ ë ---\n\n"
                        f"--- FAQ ë°ì´í„° í˜•ì‹ ì‹œì‘ (ì •í™•íˆ 5ê°œ í•­ëª©) ---\n<FAQ_DATA>\n"
                        f"Q1: [ì—¬í–‰ìë“¤ì´ ê°€ì¥ ê¶ê¸ˆí•´í•  ë§Œí•œ ì‹¤ìš©ì ì¸ ì²« ë²ˆì§¸ ì§ˆë¬¸ ì‘ì„± (ì˜ˆ: í‹°ì¼“ ì˜ˆë§¤ ë°©ë²•)]\nA1: [ì²« ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ìƒì„¸í•˜ê³  ì¹œì ˆí•œ ë‹µë³€ ì‘ì„±]\n"
                        f"Q2: [ë‘ ë²ˆì§¸ ì˜ˆìƒ ì§ˆë¬¸ ì‘ì„± (ì˜ˆ: ì‚¬ì§„ ì´¬ì˜ íŒ)]\nA2: [ë‘ ë²ˆì§¸ ë‹µë³€ ì‘ì„±]\n"
                        f"Q3: [ì„¸ ë²ˆì§¸ ì˜ˆìƒ ì§ˆë¬¸ ì‘ì„± (ì˜ˆ: ì†Œìš” ì‹œê°„)]\nA3: [ì„¸ ë²ˆì§¸ ë‹µë³€ ì‘ì„±]\n"
                        f"Q4: [ë„¤ ë²ˆì§¸ ì˜ˆìƒ ì§ˆë¬¸ ì‘ì„± (ì˜ˆ: ê·¼ì²˜ ë‹¤ë¥¸ ê´€ê´‘ì§€)]\nA4: [ë„¤ ë²ˆì§¸ ë‹µë³€ ì‘ì„±]\n"
                        f"Q5: [ë‹¤ì„¯ ë²ˆì§¸ ì˜ˆìƒ ì§ˆë¬¸ ì‘ì„± (ì˜ˆ: ì–´ë¦°ì´ë‚˜ ë…¸ì•½ì ë™ë°˜ ì‹œ íŒ)]\nA5: [ë‹¤ì„¯ ë²ˆì§¸ ë‹µë³€ ì‘ì„±]\n"
                        f"</FAQ_DATA>\n--- FAQ ë°ì´í„° í˜•ì‹ ë ---")
    try:
        response_gen_content = model.generate_content(prompt_parts, generation_config={"response_mime_type": "text/plain"})
        print(f"[âœ…] '{place_name}': ì½˜í…ì¸  ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
        return response_gen_content.text
    except Exception as e:
        print(f"[âŒ] '{place_name}': Gemini ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def generate_dedicated_title(place_name, post_content_summary):
    print(f"[ğŸ¤–] '{place_name}': ì „ìš© ì œëª© ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
    fallback_title = place_name
    model = genai.GenerativeModel('gemini-1.5-pro-latest')
    prompt = f"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í´ë¦­ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë§¤ìš° ì°½ì˜ì ì¸ ì—¬í–‰ ë¸”ë¡œê·¸ ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.\në‹¤ìŒ ì—¬í–‰ì§€ì™€ ê²Œì‹œë¬¼ í•µì‹¬ ë‚´ìš© ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ì‹œì„ ì„ ì¦‰ì‹œ ì‚¬ë¡œì¡ê³  ë°˜ë“œì‹œ í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ë§¤ìš° ë§¤ë ¥ì ì¸ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ ì œëª©ì„ **ì˜¤ì§ í•˜ë‚˜ë§Œ, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì œëª© í…ìŠ¤íŠ¸ ìì²´ë§Œ** ìƒì„±í•´ì£¼ì„¸ìš”.\n[ìš”êµ¬ì‚¬í•­]\n1. '{place_name}' í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ë˜, ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ í¥ë¯¸ë¡œìš´ ë°©ì‹ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.\n2. ì œëª©ì˜ ê¸¸ì´ëŠ” í•œê¸€ ê¸°ì¤€ 15ì ì´ìƒ 40ì ì´í•˜ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n3. ì˜ˆì‹œ: \"{place_name} ì—¬í–‰ì˜ ëª¨ë“  ê²ƒ: ë†“ì¹˜ì§€ ë§ì•„ì•¼ í•  ìˆ¨ì€ ëª…ì†Œ TOP 5 ì „ê²© ê³µê°œ!\"\n4. ê²°ê³¼ëŠ” ì˜¤ì§ ì œëª© í…ìŠ¤íŠ¸ë§Œì´ì–´ì•¼ í•˜ë©°, '# ì œëª©:'ê³¼ ê°™ì€ ì ‘ë‘ì–´ë‚˜ ë”°ì˜´í‘œ, ì¤„ë°”ê¿ˆ ë“±ì„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n[ì—¬í–‰ì§€ëª…]\n{place_name}\n[ê²Œì‹œë¬¼ í•µì‹¬ ë‚´ìš© ìš”ì•½]\n{post_content_summary}\nìƒì„±í•  ì œëª©:"

    for i in range(3):
        try:
            print(f"[ğŸ¤–] -> ì œëª© ìƒì„± ì‹œë„ ({i+1}/3)...")
            response = model.generate_content(prompt)
            new_title = response.text.strip()
            if new_title and '\n' not in new_title and (10 <= len(new_title) <= 50):
                print(f"[âœ…] '{place_name}': ì „ìš© ì œëª© ìƒì„± ì„±ê³µ: '{new_title}'")
                return new_title
            else:
                print(f"[âš ï¸] -> ìƒì„±ëœ ì œëª©ì´ ìœ íš¨ì„± ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: '{new_title}'")
        except Exception as e:
            print(f"[âŒ] -> ì œëª© ìƒì„± ì¤‘ API ì˜¤ë¥˜ ë°œìƒ: {e}")
        if i < 2: time.sleep(2)

    print(f"[âš ï¸] '{place_name}': ì „ìš© ì œëª© ìƒì„±ì— ìµœì¢… ì‹¤íŒ¨í•˜ì—¬ í´ë°± ì œëª©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    return fallback_title

def generate_focus_keyphrase(place_name, post_content_summary):
    print(f"[ğŸ¤–] '{place_name}': ì´ˆì  í‚¤í”„ë ˆì´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    fallback_keyphrase = f"{place_name} ê°€ë³¼ë§Œí•œ ê³³"
    try:
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        prompt = f"ë‹¹ì‹ ì€ ì—¬í–‰ ë¸”ë¡œê·¸ ì „ë¬¸ SEO ì½˜í…ì¸  ì „ëµê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì›Œë“œí”„ë ˆìŠ¤ ë¸”ë¡œê·¸ ê¸€ì— ì‚¬ìš©í•  ìµœì ì˜ 'ì´ˆì  í‚¤í”„ë ˆì´ì¦ˆ'ë¥¼ ë”± í•˜ë‚˜ë§Œ ìƒì„±í•´ ì£¼ì„¸ìš”.\n[ì •ë³´]\n* ê¸€ì˜ í•µì‹¬ ì£¼ì œ: {place_name} ìƒì„¸ ì†Œê°œ ë° ì—¬í–‰ ì •ë³´\n[ê·œì¹™]\n1. '{place_name}' ë˜ëŠ” ê´€ë ¨ ì§€ë¦¬ì  ëª…ì¹­ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n2. 3~5 ë‹¨ì–´ì˜ 'ë¡±í…Œì¼ í‚¤í”„ë ˆì´ì¦ˆ' í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.\n3. ì‚¬ìš©ìì˜ ê²€ìƒ‰ ì˜ë„ê°€ ëª…í™•íˆ ë“œëŸ¬ë‚˜ëŠ” ë‹¨ì–´(ì˜ˆ: ê°€ë³¼ë§Œí•œ ê³³, í•„ìˆ˜ ì½”ìŠ¤, í›„ê¸°, íŒ)ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n4. ìƒì„±ëœ í‚¤í”„ë ˆì´ì¦ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…, ì¤„ ë°”ê¿ˆ, ë”°ì˜´í‘œ ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        response = model.generate_content(prompt)
        keyphrase = response.text.strip()
        if not keyphrase or '\n' in keyphrase or len(keyphrase.split()) < 2 or len(keyphrase.split()) > 7: return fallback_keyphrase
        print(f"[âœ…] '{place_name}': ì´ˆì  í‚¤í”„ë ˆì´ì¦ˆ ìƒì„± ì™„ë£Œ: {keyphrase}")
        return keyphrase
    except Exception as e:
        print(f"[âŒ] '{place_name}': ì´ˆì  í‚¤í”„ë ˆì´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {e}. í´ë°±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return fallback_keyphrase

def generate_meta_description(focus_keyphrase, place_name, post_content_summary):
    print(f"[ğŸ¤–] '{place_name}': ë©”íƒ€ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    fallback_description = f"'{focus_keyphrase}'ì— ëŒ€í•œ ëª¨ë“  ê²ƒ! ì…ì¥ë£Œ, êµí†µ ì •ë³´ë¶€í„° ìˆ¨ê²¨ì§„ ê´€ëŒ íŒê¹Œì§€ ì™„ë²½ ê°€ì´ë“œë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."
    try:
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        prompt = f"ë‹¹ì‹ ì€ SEO ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ì™€ 'ì´ˆì  í‚¤í”„ë ˆì´ì¦ˆ'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, êµ¬ê¸€ ê²€ìƒ‰ì— ë…¸ì¶œë  ë§¤ë ¥ì ì¸ 'ë©”íƒ€ ì„¤ëª…'ì„ í•œ ë¬¸ë‹¨ë§Œ ìƒì„±í•´ ì£¼ì„¸ìš”.\n[ì •ë³´]\n* ê¸€ì˜ í•µì‹¬ ì£¼ì œ: {place_name} ì—¬í–‰ ì •ë³´\n* ì´ˆì  í‚¤í”„ë ˆì´ì¦ˆ: {focus_keyphrase}\n[ê·œì¹™]\n1. '{focus_keyphrase}'ë¥¼ ë¬¸ì¥ ì•ˆì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ê³ , ê°€ê¸‰ì  ë¬¸ì¥ ì•ë¶€ë¶„ì— ë°°ì¹˜í•˜ì„¸ìš”.\n2. ê¸€ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©° ê¶ê¸ˆì¦ì„ ìì•„ë‚´ëŠ” ë¬¸êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n3. í´ë¦­ì„ ìœ ë„í•˜ëŠ” ë¬¸êµ¬(Call to Action)ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.\n4. ì „ì²´ ê¸¸ì´ëŠ” í•œê¸€ ê¸°ì¤€ 120ì ì´ìƒ, 150ì ì´í•˜ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n5. ìƒì„±ëœ ë©”íƒ€ ì„¤ëª… ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…, ì¤„ ë°”ê¿ˆ, ë”°ì˜´í‘œ ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        response = model.generate_content(prompt)
        description = response.text.strip()
        if not (110 <= len(description) <= 160): return fallback_description
        print(f"[âœ…] '{place_name}': ë©”íƒ€ ì„¤ëª… ìƒì„± ì™„ë£Œ.")
        return description
    except Exception as e:
        print(f"[âŒ] '{place_name}': ë©”íƒ€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}. í´ë°±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return fallback_description

def generate_tags(place_name, post_content_summary):
    print(f"[ğŸ¤–] '{place_name}': ê²Œì‹œë¬¼ íƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    fallback_tags = [place_name, f"{place_name.split()[-1]} ì—¬í–‰", f"{place_name} ê°€ë³¼ë§Œí•œê³³", f"{place_name} ì¶”ì²œ"]
    try:
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        prompt = f"ë‹¹ì‹ ì€ SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì—¬í–‰ì§€ì— ëŒ€í•œ ë¸”ë¡œê·¸ ê¸€ì˜ í•µì‹¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ê²€ìƒ‰ ìµœì í™”ì— ê°€ì¥ íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ 5~10ê°œë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ëœ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n[ìš”êµ¬ì‚¬í•­]\n- '{place_name}'ì„(ë¥¼) í¬í•¨í•œ í•µì‹¬/ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¡°í™”ë¡­ê²Œ í¬í•¨í•˜ì„¸ìš”.\n- ê° í‚¤ì›Œë“œëŠ” ì‹¤ì œ ê²€ìƒ‰ì–´ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ì›Œì•¼ í•©ë‹ˆë‹¤.\n- ê²°ê³¼ëŠ” ì˜¤ì§ 'í‚¤ì›Œë“œ1,í‚¤ì›Œë“œ2,í‚¤ì›Œë“œ3' í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n[ì—¬í–‰ì§€ ë° ê¸€ ë‚´ìš© ìš”ì•½]\nì—¬í–‰ì§€: {place_name}\në‚´ìš© ìš”ì•½: {post_content_summary[:500]}"
        response = model.generate_content(prompt)
        tags_string = response.text.strip()
        tags = [tag.strip() for tag in tags_string.split(',') if tag.strip()][:10]
        if not tags: return fallback_tags
        print(f"[âœ…] '{place_name}': íƒœê·¸ {len(tags)}ê°œ ìƒì„± ì™„ë£Œ.")
        return tags
    except Exception as e:
        print(f"[âŒ] '{place_name}': íƒœê·¸ ìƒì„± ì‹¤íŒ¨: {e}. í´ë°±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return fallback_tags

def extract_table_data_and_format_html(raw_content, place_name):
    try:
        print(f"[âš™ï¸] '{place_name}': ìš”ì•½ í…Œì´ë¸” ë°ì´í„° íŒŒì‹± ë° HTML ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        table_data_match = re.search(r'<TABLE_DATA>(.*?)</TABLE_DATA>', raw_content, re.DOTALL)
        if not table_data_match: return "", raw_content
        table_data_str = table_data_match.group(1).strip()
        content_without_table = raw_content.replace(table_data_match.group(0), '').strip()
        table_data = {}
        for line in table_data_str.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1); value = value.strip().strip('[]')
                table_data[key.strip()] = value
        if not table_data: return "", content_without_table
        html = f'<div style="margin-bottom: 2.5em;">\n<h3 style="margin-bottom: 0.5em;"><strong>{place_name} í•œëˆˆì— ë³´ê¸°</strong></h3>\n'
        html += '<table style="width: 100%; border-collapse: collapse; font-size: 16px;">\n<tbody>\n'
        for key, value in table_data.items():
            html += '<tr style="border-bottom: 1px solid #e0e0e0;">\n'
            html += f'<th scope="row" style="width: 130px; min-width: 130px; white-space: nowrap; background-color: #f7f7f7; padding: 14px; text-align: left; font-weight: bold; vertical-align: top;">{key}</th>\n'
            if key == "ê³µì‹ ì›¹ì‚¬ì´íŠ¸" and value.startswith('http'):
                html += f'<td style="padding: 14px; vertical-align: top;"><a href="{value}" target="_blank" rel="noopener noreferrer">{value}</a></td>\n'
            else:
                html += f'<td style="padding: 14px; vertical-align: top;">{value}</td>\n'
            html += '</tr>\n'
        html += '</tbody>\n</table>\n</div>\n'
        print(f"[âœ…] '{place_name}': ìš”ì•½ í…Œì´ë¸” HTML ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
        return html, content_without_table
    except Exception as e:
        print(f"[âŒ] í…Œì´ë¸” ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "", raw_content

def extract_faq_data_and_format_html(raw_content):
    try:
        print(f"[âš™ï¸] FAQ ë°ì´í„° íŒŒì‹± ë° HTML ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        faq_data_match = re.search(r'<FAQ_DATA>(.*?)</FAQ_DATA>', raw_content, re.DOTALL)
        if not faq_data_match: return "", raw_content, []
        faq_data_str = faq_data_match.group(1).strip()
        content_without_faq = raw_content.replace(faq_data_match.group(0), '').strip()
        qas = re.findall(r'Q\d+:\s*(.*?)\s*\n\s*A\d+:\s*(.*)', faq_data_str)
        if not qas: return "", content_without_faq, []
        html_content = '<div class="faq-section" style="margin-top: 2.5em; border-top: 2px solid #f0f0f0; padding-top: 2em;">\n'
        html_content += '<h3 style="margin-bottom: 1em;"><strong>ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)</strong></h3>\n'
        for i, (question, answer) in enumerate(qas):
            html_content += '<details style="border: 1px solid #e0e0e0; border-radius: 5px; padding: 15px; margin-bottom: 10px;"'
            if i == 0: html_content += ' open'
            html_content += '>\n'
            html_content += f'<summary style="cursor: pointer; font-weight: bold; font-size: 1.1em; list-style-position: inside; display: list-item;">Q. {question}</summary>\n'
            html_content += f'<div style="margin-top: 10px; padding-top: 10px; border-top: 1px solid #eee;"><p>{answer}</p></div>\n'
            html_content += '</details>\n'
        html_content += '</div>\n'
        print(f"[âœ…] FAQ ì•„ì½”ë””ì–¸ HTML ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
        return html_content, content_without_faq, qas
    except Exception as e:
        print(f"[âŒ] FAQ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "", raw_content, []

def create_gallery_html(image_urls, place_name):
    if not image_urls: return ""
    print(f"[âš™ï¸] '{place_name}': {len(image_urls)}ê°œ ì´ë¯¸ì§€ë¡œ Masonry ê°¤ëŸ¬ë¦¬ HTML ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    gallery_html = '<div class="masonry-gallery">\n'
    for url in image_urls:
        alt_text = f"{place_name} ê°¤ëŸ¬ë¦¬ ì´ë¯¸ì§€"
        gallery_html += f'<div class="masonry-item"><img src="{url}" alt="{alt_text}" loading="lazy"/></div>\n'
    gallery_html += '</div>\n'
    print(f"[âœ…] '{place_name}': Masonry ê°¤ëŸ¬ë¦¬ HTML ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    return gallery_html

def create_Maps_html(place_name, place_id, api_key):
    print(f"[âš™ï¸] '{place_name}': Google Maps embed HTML ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        query_param = ""
        if place_id:
            query_param = f"q=place_id:{place_id}"
        else:
            query_param = f"q={urllib.parse.quote(place_name)}"

        maps_html = f'''
<div style="margin: 2em 0;">
<h4><strong><span style="color: #1a73e8;">ğŸ“</span> {place_name} ìœ„ì¹˜ í™•ì¸í•˜ê¸°</strong></h4>
<iframe
    width="100%"
    height="450"
    style="border:0; border-radius: 8px; margin-top: 1em;"
    loading="lazy"
    allowfullscreen
    referrerpolicy="no-referrer-when-downgrade"
    src="https://www.google.com/maps/embed/v1/place?key={api_key}&{query_param}">
</iframe>
</div>'''
        print(f"[âœ…] '{place_name}': Google Maps HTML ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
        return maps_html
    except Exception as e:
        print(f"[âŒ] '{place_name}': Google Maps HTML ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return ""

def search_youtube_video(place_name, category_name, api_key):
    search_query = f'"{place_name}" ì—¬í–‰ ê°€ì´ë“œ ë¸Œì´ë¡œê·¸ -ì‚¬ê±´ -ì‚¬ê³  -ë‰´ìŠ¤ -ë…¼ë€ -ì´ìŠˆ'
    print(f"[ğŸ”] '{search_query}': YouTubeì—ì„œ ê´€ë ¨ ë™ì˜ìƒì„ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    try:
        search_url = "https://www.googleapis.com/youtube/v3/search"
        params = {
            'part': 'snippet', 'q': search_query, 'key': api_key,
            'maxResults': 1, 'type': 'video', 'videoEmbeddable': 'true',
            'relevanceLanguage': 'ko'
        }
        response = requests.get(search_url, params=params, timeout=20)
        response.raise_for_status()
        results = response.json().get('items', [])
        if results:
            video_id = results[0]['id']['videoId']
            channel_title = results[0]['snippet']['channelTitle']
            print(f"[âœ…] YouTube: ì˜ìƒ ê²€ìƒ‰ ì„±ê³µ (Video ID: {video_id})")
            return video_id, channel_title
        else:
            print(f"[âš ï¸] YouTube: '{search_query}'ì— ëŒ€í•œ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None, None
    except Exception as e:
        print(f"[âŒ] YouTube API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None, None

def create_youtube_embed_html(video_id, place_name):
    if not video_id:
        return ""
    print(f"[âš™ï¸] '{place_name}': YouTube ì˜ìƒ ì„ë² ë“œ HTMLì„ ìƒì„±í•©ë‹ˆë‹¤...")
    embed_html = f'''
<div style="margin: 2em 0;">
<h4><strong><span style="color: #ff0000;">ğŸ¬</span> {place_name} ìƒìƒí•˜ê²Œ ë¯¸ë¦¬ë³´ê¸°</strong></h4>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto; margin-top: 1em;">
    <iframe
        src="https://www.youtube.com/embed/{video_id}"
        frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen
        style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border-radius: 8px;">
    </iframe>
</div>
</div>'''
    print(f"[âœ…] YouTube: ì„ë² ë“œ HTML ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    return embed_html

def parse_and_format_html(raw_text, featured_image_data, place_name, table_html="", gallery_html="", maps_html="", youtube_html=""):
    print(f"[âš™ï¸] '{place_name}': ë³¸ë¬¸ì„ HTML í˜•ì‹ìœ¼ë¡œ ê°€ê³µí•˜ê³  ëª¨ë“  ìš”ì†Œë¥¼ ì‚½ì…í•©ë‹ˆë‹¤...")
    content_for_html = re.sub(r'# ì œëª©: .*\n*', '', raw_text)
    content_for_html = re.sub(r'^---.*?---\n?', '', content_for_html, flags=re.MULTILINE).strip()
    lines = content_for_html.strip().split('\n')
    content_html_parts = []
    if featured_image_data:
        alt_text = f"{place_name} ëŒ€í‘œ ì´ë¯¸ì§€"
        caption_text = f"{place_name}ì˜ ì•„ë¦„ë‹¤ìš´ ì „ê²½"
        if featured_image_data.get('attribution'):
            caption_text += f"<br><small><i>{html.escape(featured_image_data['attribution'])}</i></small>"
        content_html_parts.append(f'<figure class="wp-block-image size-large"><img src="{featured_image_data["url"]}" alt="{alt_text}" style="width:100%; max-width:720px; height:auto; display:block; margin:1rem auto;" loading="lazy"><figcaption style="text-align:center; font-size:0.9em; color:#555;">{caption_text}</figcaption></figure>')
    if table_html: content_html_parts.append(table_html)
    temp_body_parts = []
    for line_content in lines:
        current_line_stripped = line_content.strip()
        if not current_line_stripped: continue
        if current_line_stripped.startswith("#### "):
            if temp_body_parts:
                content_html_parts.append("\n".join(temp_body_parts)); temp_body_parts = []
            heading_text = current_line_stripped.replace("#### ", "").strip()
            content_html_parts.append(f'<h4 style="margin-top: 2em; margin-bottom: 1em; font-size: 1.5em; font-weight: bold;">{heading_text}</h4>')
            if "ì—­ì‚¬" in heading_text and youtube_html:
                content_html_parts.append(youtube_html)
            if "ì°¾ì•„ê°€ëŠ” ë°©ë²•" in heading_text and maps_html:
                content_html_parts.append(maps_html)
            if "ë³¼ê±°ë¦¬" in heading_text and gallery_html:
                 content_html_parts.append(gallery_html)
        else:
            processed_line = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', current_line_stripped)
            temp_body_parts.append(f'<p style="font-size:18px; line-height:1.8; margin-bottom:1em;">{processed_line}</p>')
    if temp_body_parts: content_html_parts.append("\n".join(temp_body_parts))
    print(f"[âœ…] '{place_name}': HTML ê°€ê³µ ë° ëª¨ë“  ìš”ì†Œ ì‚½ì… ì™„ë£Œ.")
    return "\n".join(content_html_parts)

def create_sources_html(pexels_data, google_data, youtube_data):
    print("[âš™ï¸] ì½˜í…ì¸  ì¶œì²˜ ì •ë³´ HTML ë¸”ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    html_parts = ['<div class="content-sources" style="margin-top: 3em; padding: 20px; border: 1px solid #e0e0e0; border-radius: 8px; background-color: #f9f9f9; font-size: 14px;">']
    html_parts.append('<h4 style="margin-top: 0;"><strong>ì½˜í…ì¸  ì¶œì²˜</strong></h4>')
    html_parts.append('<ul style="list-style-type: disc; margin-left: 20px;">')
    pexels_photographers = {}
    has_unattributed_pexels = False
    for item in pexels_data:
        photographer_url = item.get('photographer_url')
        if photographer_url:
            if photographer_url not in pexels_photographers:
                 pexels_photographers[photographer_url] = item.get('photographer', 'Unknown')
        else:
            has_unattributed_pexels = True
    photo_sources_list = []
    for url, name in pexels_photographers.items():
        photo_sources_list.append(f'Photo by <a href="{url}" target="_blank" rel="noopener noreferrer">{name}</a> on Pexels')
    if has_unattributed_pexels:
        photo_sources_list.append('<a href="https://www.pexels.com" target="_blank" rel="noopener noreferrer">Additional photos from Pexels</a>')
    if any(item['source'] == 'Google' for item in google_data):
        photo_sources_list.append("Photos from Google")
    if photo_sources_list:
        html_parts.append('<li><strong>ì‚¬ì§„:</strong> ' + ', '.join(photo_sources_list) + '</li>')
    if youtube_data and youtube_data.get('video_id'):
        video_url = f"https://www.youtube.com/watch?v={youtube_data['video_id']}"
        channel_name = youtube_data.get('channel_title', 'YouTube')
        html_parts.append(f'<li><strong>ë™ì˜ìƒ:</strong> Video by {channel_name} on <a href="{video_url}" target="_blank" rel="noopener noreferrer">YouTube</a></li>')
    html_parts.append('</ul></div>')
    print("[âœ…] ì½˜í…ì¸  ì¶œì²˜ HTML ë¸”ë¡ ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    return "\n".join(html_parts)

def create_faq_schema_html(qas_data, place_name):
    if not qas_data:
        return ""
    print(f"[âš™ï¸] '{place_name}': FAQ ìŠ¤í‚¤ë§ˆ(JSON-LD)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    try:
        schema = {
            "@context": "https://schema.org",
            "@type": "FAQPage",
            "mainEntity": []
        }
        for question, answer in qas_data:
            schema["mainEntity"].append({
                "@type": "Question",
                "name": question.strip(),
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": answer.strip()
                }
            })
        schema_html = f'<script type="application/ld+json">\n{json.dumps(schema, indent=2, ensure_ascii=False)}\n</script>'
        print(f"[âœ…] '{place_name}': FAQ ìŠ¤í‚¤ë§ˆ ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
        return schema_html
    except Exception as e:
        print(f"[âŒ] '{place_name}': FAQ ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return ""

def ensure_tags_on_wordpress(cfg, tag_list, place_name):
    print(f"[â˜ï¸] '{place_name}': ì›Œë“œí”„ë ˆìŠ¤ì— íƒœê·¸ë¥¼ í™•ì¸í•˜ê³  ë“±ë¡í•©ë‹ˆë‹¤...")
    auth = (cfg["wp_user"], cfg["wp_app_pass"])
    headers = {'Content-Type': 'application/json'}
    tag_ids = []
    for tag_name in tag_list:
        if not tag_name: continue
        try:
            res = requests.get(f"{cfg['wp_api_base']}/tags", auth=auth, params={"search": tag_name}, headers=headers, timeout=10)
            res.raise_for_status()
            existing_tags = res.json()
            found = False
            if isinstance(existing_tags, list):
                for tag_data in existing_tags:
                    if isinstance(tag_data, dict) and tag_data.get('name', '').lower() == tag_name.lower():
                        tag_ids.append(tag_data['id']); found = True; break
            if not found:
                print(f"[âš™ï¸] '{place_name}': íƒœê·¸ '{tag_name}'ì„(ë¥¼) ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
                create_res = requests.post(f"{cfg['wp_api_base']}/tags", auth=auth, json={"name": tag_name}, headers=headers, timeout=10)
                create_res.raise_for_status()
                if create_res.status_code == 201: tag_ids.append(create_res.json()['id'])
        except requests.exceptions.RequestException as e: print(f"[âŒ] '{place_name}': íƒœê·¸ API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ('{tag_name}'): {e}")
    print(f"[âœ…] '{place_name}': {len(tag_ids)}ê°œì˜ íƒœê·¸ IDë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
    return tag_ids

def post_to_wordpress(cfg, post_data):
    place_name_for_log = post_data.get('korean_slug', 'ì•Œ ìˆ˜ ì—†ëŠ” ì—¬í–‰ì§€')
    print(f"[ğŸš€] '{place_name_for_log}': ì›Œë“œí”„ë ˆìŠ¤ì— ìµœì¢… ê²Œì‹œë¬¼ ë°œí–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    auth = (cfg["wp_user"], cfg["wp_app_pass"])
    headers = {'Content-Type': 'application/json'}
    payload = {
        "title": post_data['title'], "content": post_data['content'], "status": "publish",
        "categories": [post_data['wp_category_id']], "tags": post_data['tag_ids'], "slug": post_data['korean_slug']
    }
    try:
        print(f"[âš™ï¸] 1ë‹¨ê³„ - ê²Œì‹œë¬¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        created_post_res = requests.post(f"{cfg['wp_api_base']}/posts", auth=auth, json=payload, headers=headers, timeout=30)
        created_post_res.raise_for_status()
        post_json = created_post_res.json()
        post_id, post_link = post_json.get("id"), post_json.get("link")
        if not post_id:
            print(f"[âŒ] '{place_name_for_log}': ê²Œì‹œë¬¼ ìƒì„± í›„ IDë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        print(f"[âœ…] '{place_name_for_log}': ê²Œì‹œë¬¼ ìƒì„± ì„±ê³µ! (ID: {post_id})")

        print(f"[âš™ï¸] 2ë‹¨ê³„ - SEO ë° ì¸ë„¤ì¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤...")
        fifu_payload = {"meta": {"_fifu_image_url": post_data['featured_image_url']}}
        requests.post(f"{cfg['wp_api_base']}/posts/{post_id}", auth=auth, json=fifu_payload, headers=headers, timeout=20)
        print("[âœ…] FIFU ì¸ë„¤ì¼ ì„¤ì • ì™„ë£Œ.")

        yoast_payload = { "post_id": post_id, "focus_keyphrase": post_data['focus_keyphrase'], "meta_description": post_data['meta_description'] }
        yoast_url = f"{cfg['wp_url'].rstrip('/')}/wp-json/my-api/v1/update-seo"
        requests.post(yoast_url, auth=auth, json=yoast_payload, headers=headers, timeout=20)
        print("[âœ…] Yoast SEO ë©”íƒ€ë°ì´í„° ì„¤ì • ì™„ë£Œ.")

        print(f"[ğŸ‰] '{place_name_for_log}': ëª¨ë“  ì‘ì—… ì™„ë£Œ! ë°œí–‰ëœ ê¸€ ì£¼ì†Œ: {post_link}")
    except requests.exceptions.RequestException as e:
        print(f"[âŒ] '{place_name_for_log}': ì›Œë“œí”„ë ˆìŠ¤ ê²Œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if 'created_post_res' in locals() and created_post_res is not None: print(f"ì‘ë‹µ: {created_post_res.text[:500]}...")
    except Exception as e:
        print(f"[âŒ] '{place_name_for_log}': ì›Œë“œí”„ë ˆìŠ¤ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")

def process_single_place(cfg, place_name, current_category_id):
    category_name = CATEGORY_ID_TO_NAME.get(current_category_id, "")
    print(f"\n{'='*15} '{place_name}' ({category_name}) ì²˜ë¦¬ ì‹œì‘ {'='*15}")
    try:
        place_details = get_google_place_details(cfg, place_name, category_name)
        if not place_details:
            print(f"[âš ï¸] '{place_name} ({category_name})': Google Places ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•´ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False

        pexels_photos_data = search_pexels_images(cfg, place_name, category_name)
        google_photos_data = place_details.get('images', [])
        all_photos_data = pexels_photos_data + google_photos_data
        if not all_photos_data:
            print(f"[âš ï¸] '{place_name} ({category_name})': ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False

        print(f"[âš™ï¸] '{place_name}': ìˆ˜ì§‘ëœ {len(all_photos_data)}ê°œ ì´ë¯¸ì§€ì˜ URL ì¶”ì  ë° ìµœì¢… ê²€ì¦...")
        validated_images_data = []
        for image_data in all_photos_data:
            final_url = get_final_redirected_url(image_data['url'])
            if final_url and validate_image_url(final_url):
                image_data['url'] = final_url
                validated_images_data.append(image_data)
            time.sleep(0.1)

        if not validated_images_data:
            print(f"[âŒ] '{place_name}': ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ì—†ì–´ ìµœì¢… ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return False
        print(f"[âœ…] ìµœì¢… ìœ íš¨ ì´ë¯¸ì§€ {len(validated_images_data)}ê°œ í™•ë³´.")

        featured_image_data = validated_images_data[0]
        gallery_images_urls = [item['url'] for item in validated_images_data[1:]]

        raw_content_full, table_html, raw_content_body, faq_html, qas_data = None, "", "", "", []
        for i in range(3):
            print(f"[ğŸ¤–] ì½˜í…ì¸  ìƒì„± ì‹œë„ ({i+1}/3)...")
            raw_content_full = generate_gemini_content(place_name, place_details, validated_images_data)
            if raw_content_full:
                table_html, content_after_table = extract_table_data_and_format_html(raw_content_full, place_name)
                faq_html, raw_content_body, qas_data = extract_faq_data_and_format_html(content_after_table)
                if table_html and faq_html and raw_content_body:
                    print(f"[âœ…] ì‹œë„ {i+1}/3: í…Œì´ë¸” ë° FAQ ë°ì´í„° ìƒì„± ì„±ê³µ."); break
            print(f"[âš ï¸] ì‹œë„ {i+1}/3: í…Œì´ë¸” ë˜ëŠ” FAQ ë°ì´í„°ê°€ ëˆ„ë½ë˜ì–´ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            if i < 2: time.sleep(3)

        if not raw_content_full or not raw_content_body:
            print(f"[âŒ] '{place_name}': ì½˜í…ì¸  ìƒì„±ì— ìµœì¢… ì‹¤íŒ¨í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return False

        video_id, channel_title = search_youtube_video(place_name, category_name, cfg["google_places_api_key"])
        youtube_html = create_youtube_embed_html(video_id, place_name)
        maps_html = create_Maps_html(place_name, place_details.get('place_id'), cfg["google_places_api_key"])
        gallery_html = create_gallery_html(gallery_images_urls, place_name)

        # (â­ï¸ UnboundLocalError ìˆ˜ì •ì„ ìœ„í•´ ì½”ë“œ ìˆœì„œ ë³€ê²½ â­ï¸)
        # 1. ë³¸ë¬¸ HTMLì„ ë¨¼ì € ìƒì„±í•©ë‹ˆë‹¤.
        body_html_content = parse_and_format_html(raw_content_body, featured_image_data, place_name, table_html, gallery_html, maps_html, youtube_html)

        # 2. ìƒì„±ëœ ë³¸ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ SEOìš© ìš”ì•½ë³¸ê³¼ ìµœì¢… ì œëª©ì„ ìƒì„±í•©ë‹ˆë‹¤.
        summary_for_seo = "".join(re.findall(r'<p>(.*?)</p>', body_html_content, re.DOTALL))[:500]
        title = generate_dedicated_title(place_name, summary_for_seo)

        # 3. ë‚˜ë¨¸ì§€ ë¶€ê°€ ì •ë³´ë“¤ì„ ìƒì„±í•˜ê³  ìµœì¢… ì½˜í…ì¸ ë¥¼ ì¡°ë¦½í•©ë‹ˆë‹¤.
        youtube_data_for_source = {"video_id": video_id, "channel_title": channel_title}
        sources_html = create_sources_html(pexels_photos_data, google_photos_data, youtube_data_for_source)
        faq_schema_html = create_faq_schema_html(qas_data, place_name)
        final_html_content = body_html_content + faq_html + sources_html + faq_schema_html

        focus_keyphrase = generate_focus_keyphrase(place_name, summary_for_seo)
        meta_description = generate_meta_description(focus_keyphrase, place_name, summary_for_seo)
        tags = generate_tags(place_name, summary_for_seo)
        tag_ids = ensure_tags_on_wordpress(cfg, tags, place_name)

        final_post_data = {
            'title': title, 'content': final_html_content, 'tag_ids': tag_ids,
            'featured_image_url': featured_image_data['url'], 'focus_keyphrase': focus_keyphrase,
            'meta_description': meta_description, 'korean_slug': place_name.replace(" ", "-"),
            'wp_category_id': current_category_id
        }

        if not title or not final_post_data.get('content'):
            print(f"[âŒ] '{place_name}': ìµœì¢… ì½˜í…ì¸ (ì œëª© ë˜ëŠ” ë³¸ë¬¸)ê°€ ë¹„ì–´ìˆì–´ ë°œí–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return False

        post_to_wordpress(cfg, final_post_data)
        return True

    except Exception as e:
        print(f"[âŒ] '{place_name} ({category_name})' ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ìµœìƒìœ„ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        return False

def load_published_log(log_file):
    print(f"[âš™ï¸] ë°œí–‰ ê¸°ë¡ë¶€ '{log_file}'ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    if not os.path.exists(log_file):
        try:
            with open(log_file, 'w', encoding='utf-8') as f: pass
            print("[ğŸ’¡] ë°œí–‰ ê¸°ë¡ íŒŒì¼ì´ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            return set()
        except Exception as e:
            print(f"[âŒ] ë°œí–‰ ê¸°ë¡ íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return set()
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            return set(line.strip() for line in f if line.strip())
    except Exception as e:
        print(f"[âŒ] ë°œí–‰ ê¸°ë¡ íŒŒì¼ '{log_file}'ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return set()

def append_to_published_log(log_file, place_name):
    try:
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(place_name + '\n')
        print(f"[ğŸ’¾] '{place_name}' ë°œí–‰ ê¸°ë¡ ì™„ë£Œ.")
    except Exception as e:
        print(f"[âŒ] ë°œí–‰ ê¸°ë¡ íŒŒì¼ '{log_file}'ì— ì“°ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def run_automation_cycle(cfg):
    print("\n" + "="*20 + " ìë™ í¬ìŠ¤íŒ… ì‚¬ì´í´ ì‹œì‘ " + "="*20)

    published_places = load_published_log(PUBLISHED_LOG_FILE)
    print(f"[â„¹ï¸] í˜„ì¬ê¹Œì§€ ë°œí–‰ëœ ê¸€: {len(published_places)}ê°œ")

    unpublished_by_category = {}
    total_unpublished_count = 0
    ordered_category_ids = list(CATEGORY_ID_TO_NAME.keys())

    for category_id in ordered_category_ids:
        if category_id in TARGET_PLACES_OVERSEAS:
            places_list = TARGET_PLACES_OVERSEAS.get(category_id, [])
            unpublished_places = [p for p in places_list if p and p.strip() and p.strip() not in published_places]
            if unpublished_places:
                unpublished_by_category[category_id] = unpublished_places
                total_unpublished_count += len(unpublished_places)

    if total_unpublished_count == 0:
        print("\n[ğŸ‰] ëª¨ë“  ì—¬í–‰ì§€ì— ëŒ€í•œ ê¸€ ë°œí–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ìƒˆë¡œ ë°œí–‰í•  ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("="*61)
        return

    print(f"[â„¹ï¸] ë°œí–‰ ëŒ€ìƒ ì—¬í–‰ì§€: ì´ {total_unpublished_count}ê°œ ë°œê²¬")

    active_categories = [cat_id for cat_id in ordered_category_ids if cat_id in unpublished_by_category and unpublished_by_category[cat_id]]

    succeeded_count_this_run = 0
    if not active_categories:
        print("[ğŸ’¡] ë°œí–‰í•  ê¸€ì´ ìˆëŠ” ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        category_cycler = itertools.cycle(active_categories)
        max_attempts = total_unpublished_count + len(active_categories)
        attempts = 0

        while succeeded_count_this_run < MAX_POSTS_PER_RUN and attempts < max_attempts:
            current_category_id = next(category_cycler)

            if unpublished_by_category.get(current_category_id):
                place_name = unpublished_by_category[current_category_id].pop(0)

                print(f"\n--- ë‹¤ìŒ ëŒ€ìƒ ì²˜ë¦¬ ({succeeded_count_this_run + 1}/{MAX_POSTS_PER_RUN}) ---")

                if process_single_place(cfg, place_name, current_category_id):
                    append_to_published_log(PUBLISHED_LOG_FILE, place_name)
                    succeeded_count_this_run += 1

                    if sum(len(v) for v in unpublished_by_category.values()) == 0:
                        print("[ğŸ’¡] ë°œí–‰í•  ëª¨ë“  ê¸€ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
                        break

                    if succeeded_count_this_run < MAX_POSTS_PER_RUN:
                         print(f"\n--- ë‹¤ìŒ ì²˜ë¦¬ê¹Œì§€ {POST_DELAY_SECONDS}ì´ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤... ---")
                         time.sleep(POST_DELAY_SECONDS)

            if not unpublished_by_category.get(current_category_id) and current_category_id in active_categories:
                active_categories.remove(current_category_id)
                if not active_categories: break
                category_cycler = itertools.cycle(active_categories)

            attempts += 1

    print("\n" + "="*21 + " ìë™ í¬ìŠ¤íŒ… ì‚¬ì´í´ ì¢…ë£Œ " + "="*21)
    print(f"ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì´ {succeeded_count_this_run}ê°œì˜ ê¸€ì„ ì„±ê³µì ìœ¼ë¡œ ë°œí–‰í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    script_start_time = time.time()
    config = load_configuration()
    if config:
        run_automation_cycle(config)
    script_end_time = time.time()
    print(f"\nì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œê°„: {script_end_time - script_start_time:.2f}ì´ˆ")
